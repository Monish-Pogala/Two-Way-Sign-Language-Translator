# Two-Way-Sign-Language-Translator

Project Launch: Two-Way Sign Language Translator ğŸ¤ğŸ§â€â™€ï¸ğŸ—£ï¸

Github link: https://github.com/Monish0315/SIGN-LANGUAGE-TRANSLATOR-YOLO11

Excited to share my latest project â€” a real-time, two-way sign language translator designed to bridge the communication gap between sign language users and non-signers.

ğŸ” What it does:
This system enables smooth, bidirectional communication by:

Translating sign language to speech/text using computer vision and deep learning (YOLOv11).

Converting text or voice inputs to sign language using animated sign language GIFs.

ğŸ§  Core Technologies:

YOLOv11 for hand gesture detection

Pyttsx3 for text-to-speech conversion

Google Speech Recognition API for voice input

Hugging Face for sentence correction

Python Imaging Library (PIL) for real-time GIF playback

ğŸ’¡ Key Features:

Real-time sign detection and translation

Editable text outputs for improved accuracy

Smooth, natural playback of sign language

Modular, scalable design for future expansion

ğŸŒ This project not only enhances accessibility but also promotes inclusivity by making communication more seamless for the deaf and hard-of-hearing communities.

Iâ€™d love to connect with others working in AI for accessibility, assistive tech, or inclusive design â€” letâ€™s collaborate and innovate together!

#AI #MachineLearning #DeepLearning #ComputerVision #Accessibility #SignLanguage #AssistiveTechnology #Python #Innovation #InclusiveDesign
