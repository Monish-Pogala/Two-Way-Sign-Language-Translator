# Two-Way-Sign-Language-Translator

Project Launch: Two-Way Sign Language Translator 🤝🧏‍♀️🗣️

Github link: https://github.com/Monish0315/SIGN-LANGUAGE-TRANSLATOR-YOLO11

Excited to share my latest project — a real-time, two-way sign language translator designed to bridge the communication gap between sign language users and non-signers.

🔍 What it does:
This system enables smooth, bidirectional communication by:

Translating sign language to speech/text using computer vision and deep learning (YOLOv11).

Converting text or voice inputs to sign language using animated sign language GIFs.

🧠 Core Technologies:

YOLOv11 for hand gesture detection

Pyttsx3 for text-to-speech conversion

Google Speech Recognition API for voice input

Hugging Face for sentence correction

Python Imaging Library (PIL) for real-time GIF playback

💡 Key Features:

Real-time sign detection and translation

Editable text outputs for improved accuracy

Smooth, natural playback of sign language

Modular, scalable design for future expansion

🌐 This project not only enhances accessibility but also promotes inclusivity by making communication more seamless for the deaf and hard-of-hearing communities.

I’d love to connect with others working in AI for accessibility, assistive tech, or inclusive design — let’s collaborate and innovate together!

#AI #MachineLearning #DeepLearning #ComputerVision #Accessibility #SignLanguage #AssistiveTechnology #Python #Innovation #InclusiveDesign
